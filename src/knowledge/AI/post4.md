---
icon: newspaper
date: 2025-08-09
category: çŸ¥è¯†
tag:
  - äººå·¥æ™ºèƒ½
star: true
sticky: true
---

# äººå·¥æ™ºèƒ½-ç¬¬å››å‘¨å‘¨æŠ¥

æœ¬å‘¨ä»»åŠ¡ï¼šhttps://gitee.com/gaopursuit/ouc-dl/blob/master/week04.md

MobileNet_V1_V2â½¹ç»œè®²è§£ï¼šhttps://www.bilibili.com/video/BV1yE411p7L7/

MobileNet_V3â½¹ç»œè®²è§£ï¼šhttps://www.bilibili.com/video/BV1GK4y1p7uE/

ShuffleNet â½¹ç»œè®²è§£ï¼šhttps://www.bilibili.com/video/BV15y4y1Y7SY/

## æ¦‚è¿°

æœ¬å‘¨å­¦ä¹  MobileNetã€ShuffleNetã€HybridSNã€SENet&CBAM ç½‘ç»œ

## MobileNet

ä¹‹å‰æˆ‘ä»¬è¯´çš„ç½‘ç»œï¼Œè™½ç„¶æ•ˆæœä¸é”™ï¼Œä½†æ˜¯å¦‚æœæˆ‘æƒ³è®©æ‰‹æœºã€åµŒå…¥å¼è®¾å¤‡è¿è¡Œï¼Œææ€•æ€§èƒ½æ˜¯ä¸å¤Ÿçš„

äºæ˜¯ï¼ŒGoogle å›¢é˜Ÿç ”å‘çš„ MobileNet è¯ç”Ÿäº†ï¼Œä½¿å¾—ç¥ç»ç½‘ç»œæ¨¡å‹åœ¨å°å‹è®¾å¤‡ä¸Šè¿è¡Œæˆä¸ºå¯èƒ½

### MobileNet-V1

æˆ‘ä»¬çŸ¥é“ï¼Œåœ¨ä¼ ç»Ÿå·ç§¯ä¸­

- å·ç§¯æ ¸channel = è¾“å…¥ç‰¹å¾çŸ©é˜µchannel
- è¾“å‡ºç‰¹å¾çŸ©é˜µchannel = å·ç§¯æ ¸ä¸ªæ•°

![ä¼ ç»Ÿå·ç§¯](../../.vuepress/public/assets/images/post4/img1.png)

è€Œ MobileNet æå‡ºäº†ä¸€ç§å·ç§¯ï¼Œå« **DWå·ç§¯**(Depthwise Conv, æ·±åº¦å·ç§¯)ï¼Œä»–çš„ç‰¹æ€§å¦‚ä¸‹

- å·ç§¯æ ¸channel = 1
- è¾“å…¥ç‰¹å¾çŸ©é˜µchannel=å·ç§¯æ ¸ä¸ªæ•°=è¾“å‡ºç‰¹å¾çŸ©é˜µchannel

![DWå·ç§¯](../../.vuepress/public/assets/images/post4/img2.png)

ä»å›¾ä¸­æˆ‘ä»¬çœ‹åˆ°ï¼Œä¸€ä¸ª `3x3` å·ç§¯æ ¸åªè´Ÿè´£ä¸€ä¸ª channel ï¼Œä¸€å…± input_channel ä¸ªå·ç§¯æ ¸

æ­¤å¤–ï¼Œä»–ä»¬è¿˜æå‡ºäº†ä¸€ç§ **PWå·ç§¯**(Pointwise Conv, ç‚¹å·ç§¯)

![PWå·ç§¯](../../.vuepress/public/assets/images/post4/img3.png)

ä»å›¾ä¸­æˆ‘ä»¬å‘ç°ï¼Œè¿™é‡Œåˆ™æ˜¯ out_channel ä¸ª `1x1xinput_channel` çš„å·ç§¯æ ¸

è¿™ä¸¤ä¸ªéƒ¨åˆ†å…±åŒç»„æˆæˆ‘ä»¬çš„æ·±åº¦å¯åˆ†ç¦»å·ç§¯(Depthwise Separable Convolution)ï¼Œè®¡ç®—é‡åªæœ‰ä¼ ç»Ÿå·ç§¯çš„ $\frac{1}{9}$ åˆ° $\frac{1}{8}$

å…¶åŸºæœ¬ç»“æ„å¦‚å›¾

![ä¼ ç»Ÿç»“æ„(å·¦)æ­é…äº†DWå·ç§¯å’ŒPWå·ç§¯çš„æ·±åº¦å¯åˆ†ç¦»å·ç§¯åŸºæœ¬ç»“æ„(å³)](../../.vuepress/public/assets/images/post4/img4.png)

å®Œæ•´ç»“æ„å¦‚ä¸‹

![MobileNet ç»“æ„](../../.vuepress/public/assets/images/post4/img5.png)

è™½ç„¶ MobileNet æœ¬èº«å·²ç»å¾ˆç²¾ç®€ï¼Œä½†æ˜¯æœ‰æ—¶å€™ä¸€äº› App éœ€è¦æ¨¡å‹éå¸¸éå¸¸ç²¾ç®€å’Œå¿«é€Ÿï¼Œäºæ˜¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå‚æ•°

:::center

Width Multiplier å®½åº¦è¶…å‚æ•°$\alpha$

:::

å®šä¹‰æ˜¯ï¼šå¦‚æœè¾“å…¥çš„é€šé“æ˜¯ N ä¸ªï¼Œé‚£ä¹ˆè¾“å‡ºçš„é€šé“æ˜¯ $\alpha$Â·Nï¼Œå…¶ä¸­$\alpha$ä¸€èˆ¬å–(0, 1]ï¼Œä¸€èˆ¬æ˜¯å– 1ã€0.75ã€0.5ã€0.25

è¿™ä¸ªæ“ä½œå¯ä»¥å¤§å¤§é™ä½æ¨¡å‹çš„è®¡ç®—é‡ï¼Œå¯¹æ¯”å›¾å¦‚ä¸‹

![è®¡ç®—é‡å¯¹æ¯”å›¾](../../.vuepress/public/assets/images/post4/img6.png)

*æ³¨ï¼šImageNet Accuracy æ˜¯å‡†ç¡®ç‡ï¼ŒMillion Mult-Adds æ˜¯è®¡ç®—é‡ï¼ŒMillion Parameters æ˜¯ç™¾ä¸‡å‚æ•°é‡*

:::tip åŒºåˆ† FLOPS å’Œ FLOPs

- FLOPS(floating point operations per second) æ˜¯æŒ‡æ¯ç§’æµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼Œæ˜¯è®¡ç®—é€Ÿåº¦ï¼Œç”¨äºè¡¡é‡ç¡¬ä»¶æ€§èƒ½
- FLOPs(floating point operations) æ˜¯æŒ‡æµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼Œç”¨äºè¡¡é‡ç®—æ³•/æ¨¡å‹çš„å¤æ‚åº¦ï¼Œè¡¨ç¤ºè®¡ç®—é‡ï¼Œæ­¤å¤–è¿˜æœ‰ GFLOPs(æ¯ç§’ 10 äº¿æ¬¡) å’Œ TFLOPs(æ¯ç§’ 1 ä¸‡äº¿æ¬¡)

:::

æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†å¦å¤–ä¸€ä¸ªå‚æ•°

:::center

Resolution Multiplier åˆ†è¾¨ç‡è¶…å‚æ•°$\rho$

:::

è¿™ä¸ªå‚æ•°ä¸»è¦ç”¨äºè®¾ç½®è¾“å‡ºåˆ†è¾¨ç‡ï¼Œé€šè¿‡å‡å° feature map çš„åˆ†è¾¨ç‡æ¥é™ä½è®¡ç®—é‡ï¼Œæ¯”å¦‚åŸæ¥çš„é•¿å®½æ˜¯ D ï¼Œè®¾ç½® $\rho$ åæ˜¯ $\rho$Â·D

å¯¹æ¯”å›¾å¦‚ä¸‹

![å¯¹æ¯”å›¾1](../../.vuepress/public/assets/images/post4/img7.png)

ä»ä¸Šåˆ°ä¸‹ä¾æ¬¡æ˜¯ä¼ ç»Ÿå·ç§¯ã€æ·±åº¦å¯åˆ†ç¦»å·ç§¯ã€$\alpha$=0.75çš„æƒ…å†µã€$\rho$=0.714çš„æƒ…å†µ

å…¶ä¸­å·ç§¯æ ¸ 3x3 ï¼Œfeature map 14x14 è¾“å…¥é€šé“ 512 è¾“å‡ºé€šé“ 512

![å¯¹æ¯”å›¾2](../../.vuepress/public/assets/images/post4/img8.png)

æœ€ç»ˆæ€§èƒ½å¯¹æ¯”å›¾ï¼Œè¿™é‡Œä¸å¤šè¯´äº†ï¼Œå¯ä»¥è‡ªå·±æ…¢æ…¢çœ‹

![æ€§èƒ½å¯¹æ¯”](../../.vuepress/public/assets/images/post4/img9.png)

### MobileNet-V2

ç›¸æ¯” V1 ï¼ŒV2 ä¸»è¦æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- çº¿æ€§ç“¶é¢ˆ(Linear Bottleneck)å’Œå€’æ®‹å·®ç»“æ„(Inverted Residual Block)
- SE ç»“æ„
- ä¼˜åŒ–è€—æ—¶ç»“æ„

#### çº¿æ€§ç“¶é¢ˆå’Œå€’æ®‹å·®ç»“æ„

å½“æˆ‘ä»¬å•ç‹¬å»çœ‹ feature map æ¯ä¸ªé€šé“çš„åƒç´ çš„å€¼çš„æ—¶å€™ï¼Œæˆ‘ä»¬å‘ç°ï¼Œä½ç»´çš„ä¿¡æ¯æŸå¤±å¾ˆä¸¥é‡ï¼Œä½†æ˜¯é«˜ç»´çš„ä¿¡æ¯è¿˜ä¿ç•™çš„ä¸é”™ï¼Œå¦‚å›¾æ‰€ç¤º

![è¾“å‡º](../../.vuepress/public/assets/images/post4/img11.png)

è¿™ç§æŸå¤±å¯¼è‡´çš„åŸå› ï¼Œæ˜¯ä½¿ç”¨ ReLU æ¿€æ´»å‡½æ•°åå¯¼è‡´çš„ä¿¡æ¯æŸè€—ï¼Œæ—¢ç„¶å¦‚æ­¤ï¼Œæˆ‘ä»¬æœ‰ä¸¤ç§è§£å†³æ–¹æ³•

- æ›´æ¢ä¸ºçº¿æ€§æ¿€æ´»å‡½æ•°å‡å°‘ä¿¡æ¯æŸå¤±
- å¢åŠ é€šé“æ•°ï¼Œç›¸å¯¹æ¥è¯´ï¼Œä¿¡æ¯æŸå¤±æ›´å°‘ä¸€äº›

åœ¨å¢åŠ é€šé“æ•°è¿™ä¸€å—ï¼Œåˆ™ä½¿ç”¨äº†å€’æ®‹å·®ç»“æ„ï¼Œå¦‚å›¾æ‰€ç¤º

![æ®‹å·®ç»“æ„(å·¦)å€’æ®‹å·®ç»“æ„(å³)](../../.vuepress/public/assets/images/post4/img10.png)

![å€’æ®‹å·®ç»“æ„å…·ä½“æ“ä½œ](../../.vuepress/public/assets/images/post4/img12.png)

å…¶ä¸­ k å’Œ k' æ˜¯æŒ‡é€šé“æ•°ï¼Œs æ˜¯æŒ‡ strideï¼Œt æ˜¯æ‹“å±•å› å­

ä¸æ®‹å·®ç»“æ„ç›¸åï¼Œå€’æ®‹å·®ç»“æ„ä½¿ç”¨äº† 1x1 å·ç§¯å‡ç»´ï¼Œç»è¿‡ DW å·ç§¯åå†ç»è¿‡ 1x1 å·ç§¯é™ç»´ï¼Œä½†è¦æ³¨æ„çš„æ˜¯ï¼Œå€’æ®‹å·®ç»“æ„ä¸­åŸºæœ¬ä½¿ç”¨ ReLU6 æ¿€æ´»å‡½æ•°ï¼Œè€Œåœ¨æœ€å 1x1 å·ç§¯å±‚é™ç»´æ—¶ï¼Œåˆ™ä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°

æ­¤å¤–ï¼Œåœ¨å€’æ®‹å·®ç»“æ„ä¸­ï¼Œå¹¶éæ‰€æœ‰å€’æ®‹å·®ç»“æ„éƒ½æœ‰ shortcut è¿æ¥ï¼Œè€Œæ˜¯ stride=1 **å¹¶ä¸”** è¾“å…¥ç‰¹å¾çŸ©é˜µå’Œè¾“å‡ºç‰¹å¾çŸ©é˜µ shape ç›¸åŒæ—¶æ‰æœ‰(æ¯•ç«Ÿ shape ä¸åŒåšä¸äº†åŠ æ³•è¿ç®—)

![shortcut](../../.vuepress/public/assets/images/post4/img14.png)

ä»–çš„è¯¦ç»†ç½‘ç»œç»“æ„å¦‚ä¸‹

![å…·ä½“ç»“æ„](../../.vuepress/public/assets/images/post4/img13.png)

å…¶ä¸­ï¼Œt è¡¨ç¤ºæ‹“å±•å› å­ï¼Œc è¡¨ç¤ºè¾“å‡ºé€šé“æ•°ï¼Œn è¡¨ç¤ºç»“æ„çš„é‡å¤æ¬¡æ•°ï¼Œs è¡¨ç¤º stride

è¯´äº†è¿™ä¹ˆå¤šï¼Œæ¥çœ‹çœ‹åœ¨ ImageNet ä¸Šçš„æ€§èƒ½è¡¨ç°å§

![æ€§èƒ½è¡¨ç°](../../.vuepress/public/assets/images/post4/img15.png)

#### ä»£ç å®ç°

```python
from torch import nn
import torch

def _make_divisible(ch, divisor=8, min_ch=None):
    """
    æ­¤å‡½æ•°å–è‡ªåŸå§‹ tf å­˜å‚¨åº“ã€‚
    å®ƒç¡®ä¿æ‰€æœ‰å›¾å±‚éƒ½å…·æœ‰å¯è¢« 8 æ•´é™¤çš„é€šé“æ•°
    å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°ï¼š
    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py
    """
    if min_ch is None:
        min_ch = divisor
    new_ch = max(min_ch, int(ch + divisor / 2) // divisor * divisor)
    # ç¡®ä¿å‘ä¸‹èˆå…¥ä¸ä¼šå‡å°‘è¶…è¿‡ 10%
    if new_ch < 0.9 * ch:
        new_ch += divisor
    return new_ch


class ConvBNReLU(nn.Sequential): # å…ˆè¿‡å·ç§¯ï¼Œç„¶åè¿‡ BNï¼Œæœ€åè¿‡ ReLU ä¸€ç«™å¼è§£å†³
    def __init__(self, in_channel, out_channel, kernel_size=3, stride=1, groups=1):# groups=1 æ™®é€šå·ç§¯
        padding = (kernel_size - 1) // 2
        super(ConvBNReLU, self).__init__(
            nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding, groups=groups, bias=False),
            nn.BatchNorm2d(out_channel),
            nn.ReLU6(inplace=True)
        )

# å€’æ®‹å·®ç»“æ„
class InvertedResidual(nn.Module):
    def __init__(self, in_channel, out_channel, stride, expand_ratio):#expand_ratio æ‰©å±•å› å­
        super(InvertedResidual, self).__init__()
        hidden_channel = in_channel * expand_ratio # æ‹“å±•ï¼Œè‡ªç„¶æ˜¯å¯¹éšè—å±‚çš„æ‹“å±•ï¼Œæƒ³ä»€ä¹ˆå‘¢ ğŸ¤”
        self.use_shortcut = stride == 1 and in_channel == out_channel 
        # åªæœ‰ stride=1 **å¹¶ä¸”** è¾“å…¥ç‰¹å¾çŸ©é˜µå’Œè¾“å‡ºç‰¹å¾çŸ©é˜µ shape ç›¸åŒæ—¶æ‰ä½¿ç”¨ shortcut

        layers = []
        if expand_ratio != 1:
            # 1x1 PW å·ç§¯ï¼Œç”¨æ¥æ‰©å…… channelï¼Œå¦‚æœæ‹“å±•å› å­æ˜¯ 1 å°±ä¸éœ€è¦è¿™ä¸€æ­¥äº†
            # å…ˆè¿‡å·ç§¯ï¼Œç„¶åè¿‡ BNï¼Œæœ€åè¿‡ ReLU ä¸€ç«™å¼è§£å†³
            layers.append(ConvBNReLU(in_channel, hidden_channel, kernel_size=1))
        layers.extend([
            # 3x3 DW å·ç§¯
            ConvBNReLU(hidden_channel, hidden_channel, stride=stride, groups=hidden_channel),
            # 1x1 PW å·ç§¯ é™ç»´å›å»(è¿™é‡Œç”¨çº¿æ€§æ¿€æ´»å‡½æ•°)
            nn.Conv2d(hidden_channel, out_channel, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channel),
        ])

        self.conv = nn.Sequential(*layers)

    def forward(self, x):
        if self.use_shortcut:
            return x + self.conv(x)
        else:
            return self.conv(x)


class MobileNetV2(nn.Module):
    def __init__(self, num_classes=1000, alpha=1.0, round_nearest=8):# Î± è¶…å‚æ•°
        super(MobileNetV2, self).__init__()
        block = InvertedResidual
        input_channel = _make_divisible(32 * alpha, round_nearest)
        last_channel = _make_divisible(1280 * alpha, round_nearest)

        # ç½‘ç»œè®¾ç½®
        inverted_residual_setting = [
            # t, c, n, s
            # å•¥æ„æ€æ‡‚å¾—éƒ½æ‡‚
            [1, 16, 1, 1],
            [6, 24, 2, 2],
            [6, 32, 3, 2],
            [6, 64, 4, 2],
            [6, 96, 3, 1],
            [6, 160, 3, 2],
            [6, 320, 1, 1],
        ]

        features = []
        # ç¬¬ä¸€å±‚å·ç§¯å±‚
        features.append(ConvBNReLU(3, input_channel, stride=2))
        # æ„å»ºå€’æ®‹å·®ç»“æ„
        for t, c, n, s in inverted_residual_setting:
            output_channel = _make_divisible(c * alpha, round_nearest)
            for i in range(n):
                stride = s if i == 0 else 1
                features.append(block(input_channel, output_channel, stride, expand_ratio=t))
                input_channel = output_channel
        # æ„å»ºæœ€åå‡ å±‚ç»“æ„
        features.append(ConvBNReLU(input_channel, last_channel, 1))
        # æˆ‘ä»¬è”åˆï¼
        self.features = nn.Sequential(*features)

        # æ„å»ºåˆ†ç±»å™¨
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.classifier = nn.Sequential(
            nn.Dropout(0.2),
            nn.Linear(last_channel, num_classes)
        )

        # æƒé‡åˆå§‹åŒ–
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out') # ç»å…¸å‡¯æ˜åˆå§‹åŒ–
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.zeros_(m.bias)

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x
```

### MobileNet-V3

V3 ç›¸æ¯”äº V2 ä¸»è¦æœ‰ä»¥ä¸‹æ”¹è¿›

- ä½¿ç”¨æ–°**æ¿€æ´»å‡½æ•°**
- **SE(Squeeze-and-Excitation)æ¨¡å—**
- é‡è®¾è®¡**è€—æ—¶çš„ç½‘ç»œå±‚**

#### æ–°æ¿€æ´»å‡½æ•°

è¿™é‡Œä¸»è¦å¼•å…¥äº†ä¸¤ä¸ªæ¿€æ´»å‡½æ•°ï¼Œä¸€ä¸ªæ˜¯ `h-Sigmoid`ï¼Œå¯¹æ ‡ Sigmoid ï¼Œå¦å¤–ä¸€ä¸ªæ˜¯ `h-swish` å¯¹æ ‡ ReLUï¼Œç ”ç©¶äººå®¶å«å®ƒä»¬ç¡¬æ¿€æ´»å‡½æ•°

å®ƒä»¬çš„å›¾åƒæ˜¯è¿™æ ·çš„

![ç¡¬æ¿€æ´»å‡½æ•°](../../.vuepress/public/assets/images/post4/img16.png)

è€Œä»–ä»¬çš„è¡¨è¾¾å¼æ˜¯è¿™æ ·çš„

:::center

$\text{swish } x = x \cdot \sigma(x)$

$\text{h-swish}[x] = x \frac{\text{ReLU6}(x+3)}{6}$

:::

python å®ç°å¦‚ä¸‹

```python
class hswish(nn.Module):
    def forward(self, x):
        out = x * F.relu6(x + 3, inplace=True) / 6
        return out
        
class hsigmoid(nn.Module):
    def forward(self, x):
        out = F.relu6(x + 3, inplace=True) / 6
        return out
```

#### SE æ¨¡å—

å›¾ä¸­ä¸‹é¢é‚£æ¡ Bottleneck ç»“æ„ä¸‹çš„ç¥ç§˜å°è·¯ï¼Œå°±æ˜¯ SE æ¨¡å—

![SEæ¨¡å—](../../.vuepress/public/assets/images/post4/img17.png)

è¿™æ¡å°è·¯çš„å·¥ä½œè·¯çº¿å¦‚ä¸‹

![SE æ¨¡å—](../../.vuepress/public/assets/images/post4/img18.png)

å…ˆè¿‡ä¸€ä¸ªå¹³å‡æ± åŒ–ï¼Œå‹æˆä¸€ä¸ª `1x1xchannel` çš„é•¿æ¡ï¼Œç„¶åå†è¿‡ä¸¤éå…¨è¿æ¥å±‚å¹¶åˆ†åˆ«ç”¨ ReLU å’Œ H-Sigmoid æ¿€æ´»ï¼Œæœ€åæŠŠå¾—åˆ°çš„æ•°ä¹˜ç»™åŸæ¥å¼ é‡çš„æ¯ä¸€ä¸ªå…ƒç´ ï¼Œè¿™ä¸ªå°±å« SE æ¨¡å—

è¿™è¿‡äº†ä¸€éä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆè¦è¿™ä¹ˆè¿‡ï¼Ÿ

SE å…¨ç§° Squeeze-and-Excitationï¼ŒæŒ¤å‹(Squeeze) å’Œ æ¿€åŠ±(Excitation)

é€šè¿‡ä¸€ä¸ªå…¨å±€å¹³å‡æ± åŒ–çš„æ“ä½œï¼Œç›¸å½“äºå‘Šè¯‰äº†å¤§æ¨¡å‹å…¨å±€çš„ä¸€ä¸ªå¤§è‡´æƒ…å†µï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿä»å…¨å±€ä¸Šå®¡è§†é€šé“çš„é‡è¦æ€§(å¯ä»¥ç†è§£ä¸ºè®¡ç®—é€šé“çš„æƒé‡ï¼Œè®©æ¨¡å‹ä¾§é‡äºé‚£ä¸ªé€šé“)è€Œéå±€éƒ¨ä¸Š

è€Œåé¢çš„æ“ä½œåˆ™ç”¨äºæ¿€åŠ±ï¼Œç¬¬ä¸€å±‚å…¨è¿æ¥å±‚ç”¨äºé™ç»´é™ä½è®¡ç®—é‡ï¼Œç„¶åå†è¿‡ä¸€å±‚å…¨è¿æ¥å±‚ç”¨æ¥è°ƒæ•´è¾“å‡ºçš„æƒé‡åœ¨åˆç†çš„èŒƒå›´å†…ï¼Œè¿™æ ·å°±èƒ½å¤Ÿæç¤ºç½‘ç»œçš„å­¦ä¹ æ•ˆæœäº†

#### é‡æ–°è®¾è®¡çš„è€—æ—¶å±‚

è®ºæ–‡ä¸­æåˆ°ï¼Œæœ€åçš„å‡ å±‚æ€§èƒ½ä¸æ˜¯ç‰¹åˆ«å¥½ï¼Œç»è¿‡ä¼˜åŒ–ï¼Œä¸ºæ•´ä¸ªç½‘ç»œèŠ‚çœäº† 11% çš„è®¡ç®—æ—¶é—´

![è€—æ—¶å±‚](../../.vuepress/public/assets/images/post4/img19.png)

æ³¨æ„ï¼Œæœ€åçš„ 1x1 å·ç§¯ï¼Œå…¶å®å°±ç›¸å½“äºä¸€å±‚å…¨è¿æ¥å±‚

æœ€åæˆ‘ä»¬æ¥çœ‹çœ‹ç½‘ç»œçš„ç»“æ„å’Œæ€§èƒ½è¡¨ç°å§

![MobileNet-V3-Large](../../.vuepress/public/assets/images/post4/img20.png)

![MobileNet-V3-SMALL](../../.vuepress/public/assets/images/post4/img21.png)

æ³¨ï¼šSE è¡¨ç¤ºæ˜¯å¦æœ‰ SE æ¨¡å—ï¼ŒHS è¡¨ç¤ºä½¿ç”¨ h-swish æ¿€æ´»å‡½æ•°ï¼ŒRE è¡¨ç¤º ReLU ï¼Œs è¡¨ç¤º stride ï¼ŒNBN è¡¨ç¤ºä¸ä½¿ç”¨ BN

![æ€§èƒ½è¡¨ç°](../../.vuepress/public/assets/images/post4/img22.png)

å…¶ä¸­ P-1 P-2 P-3 éƒ½æ˜¯è°·æ­Œè‡ªå·±ç ”å‘çš„ Pixel æ‰‹æœº

#### ä»£ç å®ç°

```python
# è¿™é‡Œæˆ‘ç›´æ¥æ‹¿çš„å®˜æ–¹çš„å®ç°æ–¹æ³•ï¼Œçœ‹èµ·æ¥åº”è¯¥æ›´åŠ æ¸…æ¥šä¸€äº›
class InvertedResidualConfig:
    # è¿™ä¸ªç±»ç”¨äºå­˜å‚¨ MobileNetV3 è®ºæ–‡ä¸­è¡¨1å’Œè¡¨2æ‰€åˆ—å‡ºçš„é…ç½®ä¿¡æ¯ã€‚
    # æ¯ä¸ª inverted residual block çš„å‚æ•°éƒ½åœ¨è¿™é‡Œå®šä¹‰ã€‚
    def __init__(
        self,
        input_channels: int,        # è¾“å…¥é€šé“æ•°
        kernel: int,                # å·ç§¯æ ¸å¤§å°
        expanded_channels: int,     # æ‰©å±•å±‚çš„é€šé“æ•°
        out_channels: int,          # è¾“å‡ºé€šé“æ•°
        use_se: bool,               # æ˜¯å¦ä½¿ç”¨ Squeeze-and-Excitation æ¨¡å—
        activation: str,            # æ¿€æ´»å‡½æ•°ç±»å‹ ("RE" for ReLU, "HS" for Hardswish)
        stride: int,                # æ­¥é•¿
        dilation: int,              # è†¨èƒ€ç‡ (Dilation rate)
        width_mult: float,          # å®½åº¦ä¹˜æ•°ï¼Œç”¨äºè°ƒæ•´ç½‘ç»œçš„é€šé“æ•°
    ):
        self.input_channels = self.adjust_channels(input_channels, width_mult)
        self.kernel = kernel
        self.expanded_channels = self.adjust_channels(expanded_channels, width_mult)
        self.out_channels = self.adjust_channels(out_channels, width_mult)
        self.use_se = use_se
        self.use_hs = activation == "HS"  # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨ Hardswish æ¿€æ´»å‡½æ•°
        self.stride = stride
        self.dilation = dilation

    @staticmethod
    def adjust_channels(channels: int, width_mult: float):
        # è¿™ä¸ªé™æ€æ–¹æ³•ç”¨äºæ ¹æ®å®½åº¦ä¹˜æ•°è°ƒæ•´é€šé“æ•°ï¼Œå¹¶ç¡®ä¿é€šé“æ•°æ˜¯8çš„å€æ•°ã€‚
        # è¿™æ˜¯ä¸ºäº†ç¡¬ä»¶ä¼˜åŒ–çš„å¸¸è§åšæ³•ã€‚
        return _make_divisible(channels * width_mult, 8)


class InvertedResidual(nn.Module):
    # è¿™ä¸ªç±»å®ç°äº† MobileNetV3 è®ºæ–‡ç¬¬5èŠ‚ä¸­æè¿°çš„ Inverted Residual æ¨¡å—ã€‚
    # è¿™æ˜¯ MobileNetV3 çš„æ ¸å¿ƒæ„å»ºæ¨¡å—ã€‚
    def __init__(
        self,
        cnf: InvertedResidualConfig,
        norm_layer: Callable[..., nn.Module],
        se_layer: Callable[..., nn.Module] = partial(SElayer, scale_activation=nn.Hardsigmoid),
    ):
        super().__init__()
        if not (1 <= cnf.stride <= 2):
            raise ValueError("illegal stride value")

        self.use_res_connect = cnf.stride == 1 and cnf.input_channels == cnf.out_channels

        layers: List[nn.Module] = []
        activation_layer = nn.Hardswish if cnf.use_hs else nn.ReLU

        # æ‰©å±•å±‚ (Expansion phase)
        # å¦‚æœæ‰©å±•é€šé“æ•°ä¸ç­‰äºè¾“å…¥é€šé“æ•°ï¼Œåˆ™æ·»åŠ ä¸€ä¸ª1x1çš„å·ç§¯å±‚æ¥æ‰©å±•é€šé“ã€‚
        if cnf.expanded_channels != cnf.input_channels:
            layers.append(
                Conv2dNormActivation(
                    cnf.input_channels,
                    cnf.expanded_channels,
                    kernel_size=1,
                    norm_layer=norm_layer,
                    activation_layer=activation_layer,
                )
            )

        # æ·±åº¦å¯åˆ†ç¦»å·ç§¯ (Depthwise convolution)
        layers.append(
            Conv2dNormActivation(
                cnf.expanded_channels,
                cnf.expanded_channels,
                kernel_size=cnf.kernel,
                stride=cnf.stride,
                groups=cnf.expanded_channels, # groups ç­‰äºè¾“å…¥é€šé“æ•°ï¼Œå®ç°æ·±åº¦å¯åˆ†ç¦»å·ç§¯
                norm_layer=norm_layer,
                activation_layer=activation_layer,
            )
        )

        # Squeeze-and-Excitation æ¨¡å—
        if cnf.use_se:
            squeeze_channels = _make_divisible(cnf.expanded_channels // 4, 8)
            layers.append(se_layer(cnf.expanded_channels, squeeze_channels))

        # é€ç‚¹å·ç§¯ (Pointwise convolution) / çº¿æ€§ç“¶é¢ˆå±‚
        layers.append(
            Conv2dNormActivation(
                cnf.expanded_channels, cnf.out_channels, kernel_size=1, norm_layer=norm_layer, activation_layer=None
            )
        )

        self.block = nn.Sequential(*layers)
        self.out_channels = cnf.out_channels
        self._is_cn = cnf.stride > 1

    def forward(self, input: Tensor) -> Tensor:
        result = self.block(input)
        if self.use_res_connect:
            # å¦‚æœæ­¥é•¿ä¸º1ä¸”è¾“å…¥è¾“å‡ºé€šé“æ•°ç›¸åŒï¼Œåˆ™ä½¿ç”¨æ®‹å·®è¿æ¥ã€‚
            result += input
        return result


class MobileNetV3(nn.Module):
    def __init__(
        self,
        inverted_residual_setting: List[InvertedResidualConfig], # ä¸€ä¸ªåŒ…å«æ‰€æœ‰ block é…ç½®çš„åˆ—è¡¨
        last_channel: int, # æœ€åä¸€ä¸ªå·ç§¯å±‚çš„è¾“å‡ºé€šé“æ•°
        num_classes: int = 1000, # åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ•°
        block: Optional[Callable[..., nn.Module]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        dropout: float = 0.2,
        **kwargs: Any,
    ) -> None:
        super().__init__()

        if not inverted_residual_setting:
            raise ValueError("The inverted_residual_setting should not be empty")
        elif not (
            isinstance(inverted_residual_setting, Sequence)
            and all([isinstance(s, InvertedResidualConfig) for s in inverted_residual_setting])
        ):
            raise TypeError("The inverted_residual_setting should be List[InvertedResidualConfig]")

        if block is None:
            block = InvertedResidual

        if norm_layer is None:
            norm_layer = partial(nn.BatchNorm2d, eps=0.001, momentum=0.01)

        layers: List[nn.Module] = []

        # æ„å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚
        firstconv_output_channels = inverted_residual_setting[0].input_channels
        layers.append(
            Conv2dNormActivation(
                3, # è¾“å…¥å›¾åƒä¸º 3 é€šé“ (RGB)
                firstconv_output_channels,
                kernel_size=3,
                stride=2,
                norm_layer=norm_layer,
                activation_layer=nn.Hardswish,
            )
        )

        # æ ¹æ®é…ç½®æ„å»ºæ‰€æœ‰çš„ InvertedResidual æ¨¡å—
        for cnf in inverted_residual_setting:
            layers.append(block(cnf, norm_layer))

        # æ„å»ºç½‘ç»œçš„æœ€åå‡ ä¸ªå±‚
        lastconv_input_channels = inverted_residual_setting[-1].out_channels
        lastconv_output_channels = 6 * lastconv_input_channels
        layers.append(
            Conv2dNormActivation(
                lastconv_input_channels,
                lastconv_output_channels,
                kernel_size=1,
                norm_layer=norm_layer,
                activation_layer=nn.Hardswish,
            )
        )

        self.features = nn.Sequential(*layers)
        self.avgpool = nn.AdaptiveAvgPool2d(1) # è‡ªé€‚åº”å¹³å‡æ± åŒ–å±‚
        self.classifier = nn.Sequential(
            nn.Linear(lastconv_output_channels, last_channel),
            nn.Hardswish(inplace=True),
            nn.Dropout(p=dropout, inplace=True),
            nn.Linear(last_channel, num_classes),
        )

        # åˆå§‹åŒ–æƒé‡
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out")
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.zeros_(m.bias)

    def _forward_impl(self, x: Tensor) -> Tensor:
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)


def _mobilenet_v3_conf(arch: str, width_mult: float = 1.0, reduced_tail: bool = False, dilated: bool = False, **kwargs: Any):
    # è¿™ä¸ªå‡½æ•°æ ¹æ®æ¶æ„åç§° ("large" or "small") è¿”å›ç›¸åº”çš„ InvertedResidualConfig åˆ—è¡¨ã€‚
    reduce_divider = 2 if reduced_tail else 1
    dilation = 2 if dilated else 1

    bneck_conf = partial(InvertedResidualConfig, width_mult=width_mult)
    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_mult=width_mult)

    if arch == "large":
        inverted_residual_setting = [
            bneck_conf(16, 3, 16, 16, False, "RE", 1, 1),
            bneck_conf(16, 3, 64, 24, False, "RE", 2, 1),  # C1
            bneck_conf(24, 3, 72, 24, False, "RE", 1, 1),
            bneck_conf(24, 5, 72, 40, True, "RE", 2, 1),  # C2
            bneck_conf(40, 5, 120, 40, True, "RE", 1, 1),
            bneck_conf(40, 5, 120, 40, True, "RE", 1, 1),
            bneck_conf(40, 3, 240, 80, False, "HS", 2, 1),  # C3
            bneck_conf(80, 3, 200, 80, False, "HS", 1, 1),
            bneck_conf(80, 3, 184, 80, False, "HS", 1, 1),
            bneck_conf(80, 3, 184, 80, False, "HS", 1, 1),
            bneck_conf(80, 3, 480, 112, True, "HS", 1, 1),
            bneck_conf(112, 3, 672, 112, True, "HS", 1, 1),
            bneck_conf(112, 5, 672, 160 // reduce_divider, True, "HS", 2, dilation),  # C4
            bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, "HS", 1, dilation),
            bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, "HS", 1, dilation),
        ]
        last_channel = adjust_channels(1280 // reduce_divider)  # C5
    elif arch == "small":
        inverted_residual_setting = [
            bneck_conf(16, 3, 16, 16, True, "RE", 2, 1),  # C1
            bneck_conf(16, 3, 72, 24, False, "RE", 2, 1),  # C2
            bneck_conf(24, 3, 88, 24, False, "RE", 1, 1),
            bneck_conf(24, 5, 96, 40, True, "HS", 2, 1),  # C3
            bneck_conf(40, 5, 240, 40, True, "HS", 1, 1),
            bneck_conf(40, 5, 240, 40, True, "HS", 1, 1),
            bneck_conf(40, 5, 120, 48, True, "HS", 1, 1),
            bneck_conf(48, 5, 144, 48, True, "HS", 1, 1),
            bneck_conf(48, 5, 288, 96 // reduce_divider, True, "HS", 2, dilation),  # C4
            bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, "HS", 1, dilation),
            bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, "HS", 1, dilation),
        ]
        last_channel = adjust_channels(1024 // reduce_divider)  # C5
    else:
        raise ValueError(f"Unsupported model type {arch}")

    return inverted_residual_setting, last_channel


def mobilenet_v3_large(
    *, weights: Optional[Any] = None, progress: bool = True, **kwargs: Any
) -> MobileNetV3:
    """
    æ„é€ ä¸€ä¸ª MobileNetV3-Large æ¨¡å‹ã€‚

    Args:
        weights (WeightsEnum, optional): é¢„è®­ç»ƒæƒé‡ã€‚é»˜è®¤ä¸º Noneã€‚
        progress (bool, optional): å¦‚æœä¸º Trueï¼Œåˆ™æ˜¾ç¤ºä¸‹è½½é¢„è®­ç»ƒæƒé‡çš„è¿›åº¦æ¡ã€‚é»˜è®¤ä¸º Trueã€‚
        **kwargs: å…¶ä»–å¯ä»¥ä¼ é€’ç»™ MobileNetV3 çš„å‚æ•°ã€‚
    """
    inverted_residual_setting, last_channel = _mobilenet_v3_conf("large", **kwargs)
    return MobileNetV3(inverted_residual_setting, last_channel, **kwargs)


def mobilenet_v3_small(
    *, weights: Optional[Any] = None, progress: bool = True, **kwargs: Any
) -> MobileNetV3:
    """
    æ„é€ ä¸€ä¸ª MobileNetV3-Small æ¨¡å‹ã€‚

    Args:
        weights (WeightsEnum, optional): é¢„è®­ç»ƒæƒé‡ã€‚é»˜è®¤ä¸º Noneã€‚
        progress (bool, optional): å¦‚æœä¸º Trueï¼Œåˆ™æ˜¾ç¤ºä¸‹è½½é¢„è®­ç»ƒæƒé‡çš„è¿›åº¦æ¡ã€‚é»˜è®¤ä¸º Trueã€‚
        **kwargs: å…¶ä»–å¯ä»¥ä¼ é€’ç»™ MobileNetV3 çš„å‚æ•°ã€‚
    """
    inverted_residual_setting, last_channel = _mobilenet_v3_conf("small", **kwargs)
    return MobileNetV3(inverted_residual_setting, last_channel, **kwargs)
```

## ShuffleNet

### ShuffleNet-V1

è¿™ä¹Ÿæ˜¯ä¸ªç»™ç§»åŠ¨è®¾å¤‡ç”¨çš„æ¨¡å‹ï¼Œä¸è¿‡å®ƒå¼•å…¥äº†ä¸¤ä¸ªå…¨æ–°çš„æ¦‚å¿µ é€ç‚¹ç»„å·ç§¯(Pointwise Group Convolution)å’Œé€šé“æ´—ç‰Œ(Channel Shuffle)ï¼Œä»è€Œå‡å°äº†è®¡ç®—é‡

![å¯¹æ¯”å›¾](../../.vuepress/public/assets/images/post4/img23.png)

ç¾¤å·ç§¯å…¶å®ä¹‹å‰çš„ ResNeXt å°±å·²ç»è®²è¿‡äº†(å¦‚å›¾a)ï¼Œä¸è¿‡è¿™ä¸ªåˆ†ç»„çš„è¯ï¼Œæ¯ä¸€ç»„éƒ½æ˜¯éš”ç¦»å¼€çš„ï¼Œä½†æ˜¯å¦‚æœè¿™æ ·çš„è¯ï¼Œä¼šå¯¼è‡´å„ç»„çš„ä¿¡æ¯æ— æ³•æ²Ÿé€šï¼Œè€Œå¦‚æœä½¿ç”¨ 1x1 é€ç‚¹å·ç§¯ï¼Œåˆ™ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ç­‰å‰¯ä½œç”¨

äºæ˜¯ ShuffleNet æå‡ºäº†ä¸€ç§æ–¹æ¡ˆï¼Œé€šé“æ´—ç‰Œ(å¦‚å›¾b)ï¼Œé‚£å¦‚ä½•å®ç°è¿™ä¸ªæ“ä½œå‘¢ï¼Ÿ

å¦‚æœ feature map å°ºå¯¸ä¸º w x h x c1 ï¼Œåˆ†ä¸º g ä¸ªç»„ï¼Œé‚£ä¹ˆå®ƒæ˜¯è¿™æ ·æ“ä½œçš„

1. å°† feature map å±•å¼€æˆ `w x h x g x n` çš„å››ç»´çŸ©é˜µ
2. æ²¿ `w x h x g x n` çš„ g å’Œ n è½´è¿›è¡Œè½¬ç½®ï¼Œä¹Ÿå°±æ˜¯å˜æˆ `w x h x n x g`
3. å°† g å’Œ n è½´è¿›è¡Œå¹³é“ºåå¾—åˆ°æ´—ç‰Œåçš„ feature map
4. è¿›è¡Œç»„å†… 1x1 å·ç§¯æ“ä½œ

ç¤ºæ„å›¾å¦‚ä¸‹

![å‡ºè‡ª https://blog.csdn.net/zfjBIT/article/details/127557639](https://i-blog.csdnimg.cn/blog_migrate/c06632c61a90855973e5a094e5a04e19.png)

ä»£ç å®ç°

```python
import torch
def channel_shuffle(x, groups):
    batch_size, num_channels, height, width = x.size()
    channels_per_group = num_channels // groups
    print(channels_per_group)
    # reshape
    # b, c, h, w =======>  b, g, c_per, h, w
    x = x.view(batch_size, groups, channels_per_group, height, width)
    x = torch.transpose(x, 1, 2).contiguous()
    # flatten
    x = x.view(batch_size, -1, height, width)
    return x

a = torch.randn(1,15,3,3) #1x15x3x3
print(a.shape)
groups = 3
x = channel_shuffle(a, 3)
print(x.shape)
```

äº†è§£äº†å®ƒçš„æ´—ç‰Œè¿‡ç¨‹ï¼Œç°åœ¨æ¥çœ‹çœ‹å®ƒçš„åŸºæœ¬ç»“æ„

![åŸºæœ¬ç»“æ„](../../.vuepress/public/assets/images/post4/img24.png)

å…¶ä¸­ï¼Œ(a) æ˜¯ä¸€ä¸ªæ®‹å·®æ¨¡å—ï¼Œ(b) æ˜¯ ShuffleNet Unit ï¼Œå°†åŸæ¥çš„ 1x1 å·ç§¯æ¢æˆäº†é€ç‚¹ç»„å·ç§¯ï¼Œå¹¶å¢åŠ äº†æ´—ç‰Œæ“ä½œï¼Œ(c) æ˜¯åšäº†é™é‡‡æ ·çš„ ShuffleNet Unit

æ³¨æ„ (c) çš„ Concat æ“ä½œï¼Œè¿™æ˜¯é€šé“çº§è”æ“ä½œï¼Œå…¶å®å°±æ˜¯å½“æ–°çš„ channel å ä¸Šå»äº†ï¼Œå¯ä»¥å¢å¤§é€šé“ç»´åº¦çš„åŒæ—¶è¿˜é™ä½è®¡ç®—é‡

ç°åœ¨æ¥çœ‹çœ‹æ•´ä½“ç»“æ„å§

![æ•´ä½“ç»“æ„](../../.vuepress/public/assets/images/post4/img25.png)

å…³äºæ€§èƒ½å¯¹æ¯”ä¸Šï¼ŒåŸæ–‡ä¸­ç¯‡å¹…æ¯”è¾ƒé•¿ï¼Œè¿™é‡Œå°±ä¸æ”¾äº†ï¼Œæ€»ç»“å°±æ˜¯æ¯” MobileNet-V1 æ•ˆæœå¥½å‡ ä¸ªç™¾åˆ†ç‚¹

![ShuffleNet vs. MobileNet](../../.vuepress/public/assets/images/post4/img26.png)

#### ä»£ç å®ç°

ä»£ç ç¯‡å¹…æœ‰ç‚¹é•¿ï¼Œè¿™é‡Œç»™å‡ºä¸€ç¯‡æ–‡ç« å¯ä»¥çœ‹çœ‹ï¼šhttps://blog.csdn.net/weixin_47332746/article/details/142817342

### ShuffleNet-V2

V2 æ„Ÿè§‰æœ‰ç‚¹å¤æ‚ï¼Œäº†è§£ä¸€ç‚¹å°±å¯ä»¥äº†ï¼Œä¸ªäººè§‰å¾—è¿™ç¯‡æ–‡ç« å†™çš„ä¸é”™ï¼Œå¯ä»¥çœ‹çœ‹ï¼šhttps://zhuanlan.zhihu.com/p/51566209

## SENet & CBAM

SENet æ˜¯ä»€ä¹ˆå‘¢ï¼Œå¤§å®¶è¿˜è®°å¾—åˆšåˆšè¯´çš„ SE æ¨¡å—å§ï¼Œå…¶å®åŸºæœ¬ä¸Šä¹Ÿå°±é‚£æ ·ï¼Œçœ‹çœ‹å›¾å°±æ˜ç™½äº†

![SE-Inception(å·¦) å’Œ SE-ResNet(å³)](../../.vuepress/public/assets/images/post4/img27.png)

èŠ±é”€å¤§æ¦‚å¢åŠ äº† 2%~10%ï¼Œå¢åŠ çš„å‚æ•°éƒ½åœ¨ SE çš„ä¸¤ä¸ªå…¨è¿æ¥å±‚ä¸Šï¼Œä½†æ˜¯è®¡ç®—é‡å¢åŠ é‡ç†è®ºä¸Šå°äº 1%

å—ä¸äº†äº†ï¼Œç›´æ¥åšå®éªŒ

### å®éªŒ

![SE-Net å®éªŒ](../../.vuepress/public/assets/images/post4/img28.png)

æ•ˆæœç¡®å®ä¸é”™ï¼Œè€Œä¸”è®­ç»ƒçœ‹èµ·æ¥ä¹Ÿè›®å¿«çš„ï¼Œç”¨ V100-16G ç»ƒå¤§æ¦‚ 10 ç§’å¤šä¸€äº›ä¸€ä¸ª epoch

## HybridSN

è¿™ç©æ„ä¸»è¦å¼•å…¥äº†ä¸€ä¸ª 3D å·ç§¯ï¼Œå®ƒçš„åŸç†å’Œ 2D çš„å·®ä¸å¤šï¼Œä¹Ÿæ˜¯é‚£æ ·è¿åŠ¨çš„ï¼ŒæŒºå®¹æ˜“æƒ³è±¡å‡ºæ¥çš„

é‚£ä½ ä¸€å®šä¼šé—®ï¼Œè¿™å’Œå¤šé€šé“çš„å·ç§¯ï¼Œæœ‰ä»€ä¹ˆåŒºåˆ«å‘¢ï¼Ÿ

![3D ä¸ 2D å·ç§¯](../../.vuepress/public/assets/images/post4/img29.png)

çš„ç¡®ï¼Œè¿™ç©æ„çœ‹èµ·æ¥ä¼šæä¹±é€šé“ä¹‹é—´çš„å…³ç³»ï¼Œä¹Ÿä¼šæŠŠæ¨¡å‹æçš„å¾ˆå¤æ‚ï¼Œä½†æ˜¯ä½ éƒ½æƒ³åˆ°é€šé“äº†ï¼Œé‚£ 3D å·ç§¯å°±ä¸èƒ½å†å¾€ä¸Šæœ‰é€šé“äº†å—ï¼Ÿ

è¿˜çœŸæ˜¯ï¼Œè¿™ä¸ªç‰¹åˆ«çš„ channel å¯ä»¥æ˜¯è§†é¢‘çš„å¸§ï¼Œä¹Ÿå¯ä»¥æ˜¯ç«‹ä½“å›¾åƒé‡Œä¸åŒä½ç½®çš„åˆ‡ç‰‡ï¼Œå¯ä»¥ç”¨äºåŒ»ç–—é¢†åŸŸä»€ä¹ˆçš„ï¼Œæ¯”å¦‚ CT åˆ†æï¼Œä»¥åŠå¤„ç†é«˜å…‰è°±å›¾åƒ(è¿™ç§å›¾åƒé€šé“æ•°éå¸¸å¤šï¼Œéä¼ ç»Ÿ RGB)ä¹‹ç±»çš„

### å®éªŒ

![HybridSN ä»£ç ä½œä¸š](../../.vuepress/public/assets/images/post4/img30.png)

å®éªŒè¿‡ç¨‹æ²¡ä»€ä¹ˆå¥½è®²çš„äº†ï¼Œä½†æ˜¯è¦æ³¨æ„ä¸€ç‚¹ï¼Œå°±æ˜¯ä»£ç  [12] çš„ç¬¬ 24 è¡Œï¼ŒåŸæ¥æ˜¯

```python
outputs[i][j] = prediction+1
```

è¿™ä¸ª prediction æ˜¯ numpy çš„ä¸€ä¸ª argmax å¯¹è±¡å¾—åˆ°æ•°ç»„ä¸­æœ€å¤§æ•°çš„ç´¢å¼•å€¼ï¼Œä½†æ˜¯å®ƒç°åœ¨çš„å†™æ³•æ˜¯

```python
outputs[i][j] = prediction[0]+1
```

æ³¨æ„ä¸€äº›å°±å¯ä»¥äº†

## æ€è€ƒé¢˜

**`Q: è®­ç»ƒHybridSNï¼Œç„¶åå¤šæµ‹è¯•â¼æ¬¡ï¼Œä¼šå‘ç°æ¯æ¬¡åˆ†ç±»çš„ç»“æœéƒ½ä¸â¼€æ ·ï¼Œè¯·æ€è€ƒä¸ºä»€ä¹ˆï¼Ÿ`**

> A: å› ä¸ºä½¿ç”¨ `Dropout` äº†ï¼Œè€Œ `Dropout` æ˜¯è®©ç¥ç»å…ƒéšæœºå¤±æ´»çš„ï¼Œè¿™é‡Œå°±æœ‰ä¸€ä¸ªéšæœºçš„å› ç´ äº†
> æ­¤å¤–ï¼Œåœ¨è®­ç»ƒæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬å°† `shuffle` è®¾ç½®ä¸º True äº†ï¼Œè¿™æ ·å°±ä¼šéšæœºæ‰“ä¹±æ•°æ®ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªéšæœºçš„å› å­ï¼Œå› æ­¤æ¯æ¬¡åˆ†ç±»çš„ç»“æœæˆ–è®¸éƒ½æ˜¯ä¸åŒçš„

**`Q: å¦‚æœæƒ³è¦è¿›â¼€æ­¥æå‡â¾¼å…‰è°±å›¾åƒçš„åˆ†ç±»æ€§èƒ½ï¼Œå¯ä»¥å¦‚ä½•æ”¹è¿›ï¼Ÿ`**

> A: é™¤äº†ä¼˜åŒ–ç½‘ç»œç»“æ„(ä¼˜åŒ–åå‡†ç¡®ç‡åˆ°è¾¾ 97%~98%)å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å¢åŠ è®­ç»ƒçš„ä»£æ•°ï¼Œä»¥åŠä½¿ç”¨æˆ‘ä»¬ä¹‹å‰æåˆ°çš„è¿ç§»å­¦ä¹ çš„æ–¹æ³•æ¥å®ç°çŸ­æ—¶é—´å†…è¾¾åˆ°é«˜æ€§èƒ½çš„æ¨¡å‹ï¼Œå½“ç„¶æ–¹æ³•è¿˜æ˜¯å¾ˆå¤šçš„

**`Q: depth-wise conv å’Œ åˆ†ç»„å·ç§¯æœ‰ä»€ä¹ˆåŒºåˆ«ä¸è”ç³»ï¼Ÿ`**

> A: è”ç³»å°±æ˜¯å®ƒä»¬ä¿©å®é™…ä¸Šéƒ½å¯¹æ•°æ®è¿›è¡Œäº†åˆ†ç»„å¤„ç†ï¼Œä½†æ˜¯ DW ä¸åŒçš„æ˜¯ï¼Œå®ƒæ˜¯æ¯ä¸ªé€šé“ä¸€ä¸ªå·ç§¯æ ¸æ¥å¤„ç†å®ƒï¼Œç›¸å½“äºç»„æ•°å’Œé€šé“æ•°ä¸€æ ·ï¼Œå®ƒå¯ä»¥åœ¨ç²¾åº¦ä¸‹é™ä¸å¤šçš„æƒ…å†µä¸‹ï¼Œå¤§å¤§é™ä½è®¡ç®—é‡ï¼Œè€Œåˆ†ç»„å·ç§¯åˆ™æ˜¯å¯ä»¥æå‡ç²¾åº¦çš„

**`Q: SENet çš„æ³¨æ„â¼’æ˜¯ä¸æ˜¯å¯ä»¥åŠ åœ¨ç©ºé—´ä½ç½®ä¸Šï¼Ÿ`**

> A: æ ‡å‡†çš„SENetæ³¨æ„åŠ›æœºåˆ¶æ˜¯é’ˆå¯¹é€šé“ï¼Œè€Œéç›´æ¥ä½œç”¨äºç©ºé—´ä½ç½®çš„
> è™½ç„¶ SENet æ²¡æœ‰ï¼Œä½†æ˜¯ CBAM æœ‰ï¼Œå®ƒåŒæ—¶æœ‰ç©ºé—´å’Œé€šé“æ³¨æ„åŠ›ï¼Œå®ƒçš„ç©ºé—´æ³¨æ„åŠ›å°±æ˜¯å…ˆç”¨ SENet çš„æ“ä½œï¼Œæ‰¾å‡ºå“ªä¸ªé€šé“æ¯”è¾ƒé‡è¦ï¼Œç„¶åå†ç”¨ Self-Attention(å…³æ³¨è¾“å…¥åºåˆ—å†…éƒ¨å…ƒç´ ä¹‹é—´çš„ä¾èµ–å…³ç³») æ¥å®ç°ç©ºé—´å…³ç³»çš„æ„ŸçŸ¥çš„

**`Q: åœ¨ ShuffleNet ä¸­ï¼Œé€šé“çš„ shuffle å¦‚ä½•â½¤ä»£ç å®ç°ï¼Ÿ`**

> A: ä¸Šé¢å†™äº†

## å‚è€ƒçš„æ–‡ç« &è®ºæ–‡

æˆ‘è§‰å¾—è¿™äº›æ–‡ç« è®²çš„éƒ½è¿˜ä¸é”™ï¼Œæˆ‘è¿™è¾¹åªæ˜¯æµ“ç¼©äº†ä¸€ä¸‹ï¼Œåªå†™äº†é‡ç‚¹ï¼Œå¦‚æœæƒ³ä»”ç»†ä¸€ç‚¹å¯ä»¥çœ‹ä¸‹é¢çš„æ–‡ç« 

### MobileNet-V1

- https://arxiv.org/pdf/1704.04861
- https://blog.csdn.net/weixin_44023658/article/details/105962635

### MobileNet-V2

- https://arxiv.org/pdf/1801.04381
- https://blog.csdn.net/weixin_44023658/article/details/105962635

### MobileNet-V3

- https://arxiv.org/pdf/1905.02244
- https://blog.csdn.net/qq_32892383/article/details/143170942
- https://blog.csdn.net/weixin_43334693/article/details/130834849

### ShuffleNet-V1

- https://arxiv.org/pdf/1707.01083
- https://zhuanlan.zhihu.com/p/51566209
- https://blog.csdn.net/weixin_34910922/article/details/109865599
- https://blog.csdn.net/zfjBIT/article/details/127557639
- https://blog.csdn.net/weixin_47332746/article/details/142817342

### SENet & CBAM

- https://cloud.tencent.com/developer/article/1052599
- https://blog.csdn.net/Evan123mg/article/details/80058077
- https://tobefans.github.io/2020/05/08/SENet/

### HybridSN

- https://arxiv.org/pdf/1902.06701
- https://zhuanlan.zhihu.com/p/55567098